{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y55yFJka64Bb",
        "outputId": "c638ba20-c734-43b3-b7a3-2a8357b1673e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import tensorflow as tf\n",
        "from numpy import array\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Embedding\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
      ],
      "metadata": {
        "id": "9VSzzU5U75Pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '아 집가고 싶다.'"
      ],
      "metadata": {
        "id": "3PwW28NP8Hlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = text_to_word_sequence(text)\n",
        "\n",
        "print('원래 문구: ', text)\n",
        "print('토큰화', result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Rl1rIyB8qJV",
        "outputId": "df658eb4-b8d3-4d39-b91a-66dd3c1771f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원래 문구:  아 집가고 싶다.\n",
            "토큰화 ['아', '집가고', '싶다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = ['먼저 텍스트와 각 단어를 나누어 토큰화 합니다',\n",
        "        '텍스트의 단어로 토큰화 해야 딥러닝에서 인식됩니다.',\n",
        "        '토큰화 한 결과는 딥러닝에서 사용할 수 있습니다.',\n",
        "        ]"
      ],
      "metadata": {
        "id": "Z0CUOsLH83UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = Tokenizer()\n",
        "token.fit_on_texts(docs)"
      ],
      "metadata": {
        "id": "xY5EZoLd9DG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 카운트', token.word_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUeGv6Ho9SVQ",
        "outputId": "82479db3-ed15-41e8-8032-aff8e3fcbc1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 카운트 OrderedDict([('먼저', 1), ('텍스트와', 1), ('각', 1), ('단어를', 1), ('나누어', 1), ('토큰화', 3), ('합니다', 1), ('텍스트의', 1), ('단어로', 1), ('해야', 1), ('딥러닝에서', 2), ('인식됩니다', 1), ('한', 1), ('결과는', 1), ('사용할', 1), ('수', 1), ('있습니다', 1)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('문장 카운트: ', token.document_count)\n",
        "print('각 단어가 몇개의 문장에 포함되는가: ', token.word_docs)\n",
        "print('각 단어에 매겨진 인덱스 값: ', token.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUGpKbnI9cQs",
        "outputId": "4425dac1-032e-4205-9f74-ae526f0a1d39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장 카운트:  3\n",
            "각 단어가 몇개의 문장에 포함되는가:  defaultdict(<class 'int'>, {'합니다': 1, '토큰화': 3, '단어를': 1, '각': 1, '텍스트와': 1, '먼저': 1, '나누어': 1, '딥러닝에서': 2, '단어로': 1, '텍스트의': 1, '해야': 1, '인식됩니다': 1, '수': 1, '한': 1, '있습니다': 1, '결과는': 1, '사용할': 1})\n",
            "각 단어에 매겨진 인덱스 값:  {'토큰화': 1, '딥러닝에서': 2, '먼저': 3, '텍스트와': 4, '각': 5, '단어를': 6, '나누어': 7, '합니다': 8, '텍스트의': 9, '단어로': 10, '해야': 11, '인식됩니다': 12, '한': 13, '결과는': 14, '사용할': 15, '수': 16, '있습니다': 17}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = ['너무 재밌어요', '최고에요', '참 잘 만든 영화네요', '추천하고 싶은 영화 입니다.', '한번 더 보고싶네요',\n",
        "        '글쎄요', '별로에요', '생각보다 지루하네요', '연기가 어색해요', '재미없어요']"
      ],
      "metadata": {
        "id": "ELpfR5W29yjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = array([1,1,1,1,1,0,0,0,0,0])"
      ],
      "metadata": {
        "id": "vOPVUYKzgdBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = Tokenizer()"
      ],
      "metadata": {
        "id": "b3HxCgtoggSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token.fit_on_texts(docs)\n",
        "\n",
        "print(token.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB6Iq1kegqqK",
        "outputId": "eb6abc0b-fdec-478a-8d9b-411d5e166520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'너무': 1, '재밌어요': 2, '최고에요': 3, '참': 4, '잘': 5, '만든': 6, '영화네요': 7, '추천하고': 8, '싶은': 9, '영화': 10, '입니다': 11, '한번': 12, '더': 13, '보고싶네요': 14, '글쎄요': 15, '별로에요': 16, '생각보다': 17, '지루하네요': 18, '연기가': 19, '어색해요': 20, '재미없어요': 21}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = token.texts_to_sequences(docs)\n",
        "\n",
        "print('문장 숫자화: ', x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv3K2z0EhGxi",
        "outputId": "36590f69-2f1f-46f8-8f23-2458e6b9ef34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장 숫자화:  [[1, 2], [3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14], [15], [16], [17, 18], [19, 20], [21]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_x = pad_sequences(x, 10)\n",
        "\n",
        "print('패딩 결과:\\n', padded_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86AkMlyihW7S",
        "outputId": "75af9396-aed4-44e3-d634-691b25057b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "패딩 결과:\n",
            " [[ 0  0  0  0  0  0  0  0  1  2]\n",
            " [ 0  0  0  0  0  0  0  0  0  3]\n",
            " [ 0  0  0  0  0  0  4  5  6  7]\n",
            " [ 0  0  0  0  0  0  8  9 10 11]\n",
            " [ 0  0  0  0  0  0  0 12 13 14]\n",
            " [ 0  0  0  0  0  0  0  0  0 15]\n",
            " [ 0  0  0  0  0  0  0  0  0 16]\n",
            " [ 0  0  0  0  0  0  0  0 17 18]\n",
            " [ 0  0  0  0  0  0  0  0 19 20]\n",
            " [ 0  0  0  0  0  0  0  0  0 21]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_size = len(token.word_index) + 1"
      ],
      "metadata": {
        "id": "C15hg5UphrDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(word_size, 8, input_length = 10))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(padded_x, classes, epochs = 20)\n",
        "\n",
        "\n",
        "print('accuracy: %.4f' % (model.evaluate(padded_x, classes)[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsddL3Y5ij6K",
        "outputId": "65d230e0-b037-4e9c-c03a-b42a636dd9dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 1s 610ms/step - loss: 0.6906 - accuracy: 0.7000\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6891 - accuracy: 0.7000\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6875 - accuracy: 0.7000\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6859 - accuracy: 0.7000\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6844 - accuracy: 0.8000\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6828 - accuracy: 0.8000\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6812 - accuracy: 0.8000\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6797 - accuracy: 0.8000\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6781 - accuracy: 0.8000\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6765 - accuracy: 0.8000\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6749 - accuracy: 0.8000\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6733 - accuracy: 0.8000\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6717 - accuracy: 0.8000\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6701 - accuracy: 0.8000\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6684 - accuracy: 0.8000\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6667 - accuracy: 0.9000\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6651 - accuracy: 0.9000\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6634 - accuracy: 0.9000\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6617 - accuracy: 0.9000\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6600 - accuracy: 0.9000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.6582 - accuracy: 0.9000\n",
            "accuracy: 0.9000\n"
          ]
        }
      ]
    }
  ]
}